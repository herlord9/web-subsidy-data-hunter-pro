# Data Hunter Pro

一个专业的网页数据猎取工具浏览器扩展，使用现代化的技术栈实现。

## 📖 项目背景

在进行政府网站数据提取使用，用 EasyScraper 进行关键信息网页抓取时，我发现了一些限制：
- ❌ **无法勾选数据** - 不能选择性地导出特定数据行
- ❌ **导出功能受限** - 导出格式和方式有限
- ❌ **无法对接后端系统** - 不能将数据直接导入到指定的后端系统

为了解决这些问题，我决定重新开发一个功能更强大的数据抓取工具，**Data Hunter Pro** 应运而生。

## ✨ 核心特性

### 🔍 智能容器识别（而非用户手动选择）

与传统的需要用户手动选择 DOM 元素的方式不同，Data Hunter Pro 采用**智能容器识别**技术，自动检测页面中的列表容器，无需用户手动操作即可准确识别数据区域。

### 📋 多格式导出 + 勾选功能

- **JSON 导出** - 支持勾选指定网址导出为 JSON 格式
- **Excel/CSV 导出** - 支持勾选指定网址导出为 Excel 或 CSV 格式
- **复制到剪贴板** - 支持勾选指定网址复制到剪贴板
- **所有导出方式都支持勾选** - 可以精确选择需要导出的数据行

### 🔗 后端系统对接

- **直接对接后端 API** - 可将数据直接导出到指定的后端系统
- **AI 识别网站标题** - 后端接口支持 AI 识别网站标题功能
- **自动来源标识** - 录入数据的来源自动标记为"插件导入" + 当天日期（格式：`插件导入-YYYY-MM-DD`）

### 🌏 智能地区识别

- **自动推断地区信息** - 根据 URL 自动推断省市区信息
- **手动补充地区** - 如果自动识别不完整，支持手动选择省市区
- **地区数据验证** - 导出前验证地区数据完整性

### 💾 抓取器管理

- 创建、编辑、删除抓取器配置
- 支持多种抓取类型（列表、详情页）
- 高级选项配置（自动滚动、分页处理、等待时间控制）

## 🎯 网页列表提取逻辑（优先级顺序）

Data Hunter Pro 采用多层级、多策略的智能识别算法，按以下优先级顺序识别网页列表：

### 优先级 -1（最高优先级）：搜索结果区域 - Div 容器识别

**策略 0-0.1.2**：在包含"当前搜索到"、"搜索结果"、"找到.*结果"等关键词的区域中，优先查找 div 容器中包含多个链接的结构。

- 识别包含"网站内容"标题的 div 容器
- 要求容器内至少有 5 个有效链接
- 过滤掉导航链接、标题链接等无效链接
- 适用于非标准列表结构的搜索结果页面

### 优先级 0：搜索结果区域 - 标准列表识别

**策略 0-0.1.1**：在搜索结果区域中查找标准的 `ul/ol` 列表结构。

- 在搜索结果区域内查找 `ul` 或 `ol` 元素
- 要求至少有 5 个有效的 `li` 项
- 排除导航列表和分页列表
- 适用于标准的搜索结果列表

### 优先级 1：明确的搜索结果列表

**策略 0-0**：查找带有明确搜索结果标识的列表元素。

- 查找 `ul[id*="list"]`、`ul[class*="list"]`、`ul[id*="result"]`、`ul[class*="result"]` 等
- 要求至少有 2 个有效项
- 排除导航和分页列表

**策略 0-0.5**：特殊识别 - 查找包含多个 `div.msg.discuss` 的容器（适用于滑县等网站）。

**策略 0-0.6**：特殊识别 - 查找 `div.result-list` 或 `div.s-result` 结构（适用于临颍县、舞阳县、宁陵县等网站）。

### 优先级 2：通用搜索结果检测

**策略 0-1**：基于规律的通用搜索结果检测（不依赖特定类名）。

- **方法 A**：查找包含 `result`、`item`、`news`、`list` 等关键词的 div 元素
- 按 class 名称分组，选择包含至少 2 个有效项的组
- **方法 B**：查找包含长文本标题链接的元素（如曹县的 `div.row > div > a`）
- 要求链接文本长度 > 10，URL 包含 `.html`，排除导航链接

### 优先级 3：特殊结构识别

**策略 0-2**：识别包含 `a[name="docpuburl"]` 的搜索结果结构。

- 查找所有 `a[name="docpuburl"]` 元素
- 找到它们的共同父容器
- 适用于特定的文档发布系统

### 优先级 4：通用列表识别（兜底策略）

**策略 1**：获取所有可能的列表元素。

- 查找 `table`、`ul`、`[class*="list-item"]`、`[class*="result-item"]`、`[class*="search-result"]` 等
- 排除导航、菜单、广告、横幅等非内容区域
- 统计每个选择器的出现次数，选择最可能的列表容器

## 🔄 提取流程说明

1. **容器识别阶段**：按照上述优先级顺序，依次尝试识别列表容器
2. **找到即返回**：一旦找到符合条件的容器（优先级 -1、0、1），立即返回，不再继续后续策略
3. **兜底策略**：如果所有高优先级策略都失败，使用通用列表识别作为兜底
4. **数据提取**：从识别到的容器中提取标题、链接、日期等数据

## 🚀 快速开始

### 安装

```bash
# 克隆项目
git clone <repository-url>
cd web-subsidy-data-hunter-pro

# 安装依赖
npm install

# 构建扩展（默认使用测试环境）
npm run build
```

### 环境配置

插件支持三种环境：

- **测试环境**（默认）: `npm run env:test`
- **开发环境**: `npm run env:dev`
- **生产环境**: `npm run env:prod`

切换环境会自动重新编译插件。

### 加载到浏览器

1. 打开 Chrome 浏览器
2. 访问 `chrome://extensions/`
3. 开启"开发者模式"
4. 点击"加载已解压的扩展程序"
5. 选择 `dist` 文件夹

## 📖 使用方法

1. **登录系统** - 打开插件，使用账号密码登录（支持浏览器记住密码）
2. **创建抓取器** - 访问任何网页，点击扩展图标，创建新的抓取器
3. **自动识别容器** - 插件会自动识别页面中的列表容器（无需手动选择）
4. **开始抓取** - 点击"Start Scraping"开始数据抓取
5. **勾选数据** - 使用表格中的复选框精确选择要导出的行
6. **导出数据** - 选择导出格式：
   - **JSON** - 导出为 JSON 文件
   - **Excel/CSV** - 导出为 Excel 或 CSV 文件
   - **复制** - 复制到剪贴板
   - **导出到数据库** - 直接导入到后端系统（支持自动地区识别）

## 🔗 后端接口对接

### 数据导入接口

**接口路径**：`/api/chrome-data/import`

**请求方法**：POST

**请求头**：
```
Content-Type: application/json
Authorization: Bearer <access_token>
```

**请求体格式**：
```json
[
  {
    "title": "关于耕地地力保护补贴标准的公示",
    "href": "http://example.com/detail/123",
    "province": "山东省",
    "city": "菏泽市",
    "county": "牡丹区",
    "region_code": "371702",
    "source": "插件导入-2025-01-15"
  }
]
```

**数据字段说明**：
- `title`: 标题（后端 AI 接口会自动识别和优化）
- `href`: 完整的 URL 链接
- `province`: 省份
- `city`: 城市
- `county`: 区县（可选）
- `region_code`: 地区代码
- `source`: 数据来源，自动格式化为 `插件导入-YYYY-MM-DD`

### 地区推断接口

**接口路径**：`/api/chrome-data/infer-region`

**请求方法**：GET

**请求参数**：
- `url`: 要推断的 URL（支持完整 URL 或域名）

**响应格式**：
```json
{
  "province": "湖北省",
  "city": "宜昌市",
  "county": null,
  "region_code": "420500",
  "confidence": "high",
  "source": "url"
}
```

### AI 识别网站标题接口

后端系统集成了 AI 识别功能，可以自动识别和优化网站标题，确保数据质量。

## 🛠 技术栈

- **React 18** - 前端框架
- **TanStack Table v8** - 数据表格组件（支持行选择、排序、过滤）
- **PapaParse** - CSV 数据处理
- **Webpack 5** - 构建工具
- **Chrome Extension APIs** - 浏览器扩展 API

## 📁 项目结构

```
src/
├── popup/           # 弹窗界面 (React)
│   ├── components/  # UI 组件
│   │   ├── Login.js          # 登录组件
│   │   ├── DataTable.js      # 数据表格组件（支持勾选）
│   │   ├── ExportButtons.js  # 导出按钮组件
│   │   └── ...
│   ├── hooks/       # 自定义 Hooks
│   │   ├── useAuth.js        # 认证 Hook
│   │   └── useScrapers.js    # 抓取器管理 Hook
│   └── App.js       # 主应用组件
├── background/      # 后台脚本
├── content/         # 内容脚本（智能识别逻辑）
│   └── content.js   # 核心提取逻辑
├── config/          # 配置文件
│   └── api.js       # API 配置（环境切换）
├── _locales/        # 多语言文件
└── manifest.json    # 扩展配置
```

## 🔧 开发

```bash
# 开发模式（监听文件变化）
npm run dev

# 生产构建
npm run build

# 清理构建文件
npm run clean

# 切换环境
npm run env:test  # 测试环境
npm run env:dev   # 开发环境
npm run env:prod  # 生产环境
```

## 🎯 核心改进（相比 EasyScraper）

- ✅ **智能容器识别** - 自动识别列表容器，无需手动选择
- ✅ **行选择功能** - 使用 TanStack Table 的内置行选择，支持精确勾选
- ✅ **多格式导出** - JSON、Excel/CSV、复制，所有格式都支持勾选
- ✅ **后端系统对接** - 直接导入到后端系统，支持 AI 识别
- ✅ **自动来源标识** - 数据来源自动标记为"插件导入-日期"
- ✅ **智能地区识别** - 自动推断地区信息，支持手动补充
- ✅ **批量操作** - 全选/取消全选按钮
- ✅ **搜索过滤** - 实时搜索表格数据
- ✅ **排序功能** - 点击列标题进行排序
- ✅ **更好的 UI** - 现代化的界面设计

## 📄 许可证

MIT License
