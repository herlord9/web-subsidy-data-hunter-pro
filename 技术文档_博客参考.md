# Data Hunter Pro - 技术文档与功能总结

> 一个专业的网页数据猎取工具浏览器扩展，基于 React + Chrome Extension API 构建

---

## 📋 目录

1. [项目概述](#项目概述)
2. [技术架构](#技术架构)
3. [核心功能](#核心功能)
4. [技术实现细节](#技术实现细节)
5. [数据流程](#数据流程)
6. [API 集成](#api-集成)
7. [特色功能](#特色功能)
8. [使用场景](#使用场景)

---

## 项目概述

### 产品定位

**Data Hunter Pro** 是一个专业的网页数据抓取浏览器扩展，旨在帮助用户快速、准确地从网页中提取结构化数据，无需编程知识即可完成数据采集任务。

### 核心价值

- ✅ **零代码抓取** - 可视化操作，无需编写代码
- ✅ **智能识别** - 自动识别网页列表结构
- ✅ **灵活导出** - 支持 CSV、JSON、API 多种导出方式
- ✅ **配置复用** - 抓取器配置可保存和复用
- ✅ **开发辅助** - 导出 Playwright 配置，加速后端开发

### 技术栈

| 技术 | 版本 | 用途 |
|------|------|------|
| React | 18.2.0 | 前端 UI 框架 |
| TanStack Table | 8.10.7 | 数据表格组件 |
| PapaParse | 5.4.1 | CSV 数据处理 |
| Webpack | 5.88.0 | 构建工具 |
| Chrome Extension API | - | 浏览器扩展能力 |

---

## 技术架构

### 架构图

```
┌─────────────────────────────────────────────────┐
│           Chrome Extension 架构                   │
└─────────────────────────────────────────────────┘

┌──────────────┐      ┌──────────────┐      ┌──────────────┐
│   Popup UI   │◄────►│  Background  │◄────►│ Content      │
│   (React)    │      │   Script     │      │ Script       │
└──────────────┘      └──────────────┘      └──────────────┘
      │                      │                      │
      │                      │                      │
      ▼                      ▼                      ▼
┌──────────────┐      ┌──────────────┐      ┌──────────────┐
│ 用户交互界面  │      │ 消息路由      │      │ DOM 操作     │
│ 抓取器管理    │      │ 状态管理      │      │ 数据提取     │
│ 数据展示      │      │ 存储管理      │      │ 元素高亮     │
└──────────────┘      └──────────────┘      └──────────────┘
```

### 模块划分

#### 1. Popup UI (React 应用)

**位置**: `src/popup/`

**职责**:
- 用户界面交互
- 抓取器配置管理
- 数据展示和导出
- 与 Content Script 通信

**核心组件**:
- `App.js` - 主应用组件
- `ScraperList.js` - 抓取器列表
- `ScraperForm.js` - 抓取器配置表单
- `DataTable.js` - 数据表格（基于 TanStack Table）
- `ExportButtons.js` - 导出功能按钮

#### 2. Content Script

**位置**: `src/content/content.js`

**职责**:
- DOM 元素识别和提取
- 列表结构自动检测
- 数据抓取执行
- 页面元素高亮

**核心功能**:
```javascript
class EasyScraperContentScript {
  // 列表抓取
  async scrapeList() {
    // 1. 识别列表容器
    // 2. 提取列表项
    // 3. 提取字段数据
    // 4. 返回结构化数据
  }
  
  // 详情页抓取
  async scrapeDetails() {
    // 提取详情页字段
  }
  
  // 智能识别列表选项
  getListOptions() {
    // 扫描页面，找出可能的列表容器
  }
}
```

#### 3. Background Script

**位置**: `src/background/background.js`

**职责**:
- 消息路由
- 跨标签页通信
- 扩展生命周期管理

---

## 核心功能

### 1. 智能列表识别

**功能描述**: 自动扫描页面，识别所有可能的列表容器

**实现逻辑**:
```javascript
getListOptions() {
  // 1. 查找常见的列表容器选择器
  const commonSelectors = [
    'ul', 'ol', 'table tbody',
    '[class*="list"]', '[class*="item"]',
    '[id*="list"]', '[id*="item"]'
  ];
  
  // 2. 统计每个容器的子元素数量
  // 3. 过滤掉子元素少于3个的容器
  // 4. 返回候选列表供用户选择
}
```

**用户流程**:
1. 点击"开始抓取"
2. 如果检测到多个列表容器，弹出选择界面
3. 用户选择目标容器
4. 开始抓取

### 2. 数据抓取引擎

**支持类型**:
- **列表抓取器** (`type: 'list'`) - 抓取列表页数据
- **详情抓取器** (`type: 'details'`) - 抓取详情页数据

**抓取流程**:
```
1. 识别列表容器
   ↓
2. 提取所有列表项
   ↓
3. 对每个列表项：
   - 提取标题（a, h1-h6, [class*="title"]）
   - 提取链接（a[href]）
   - 提取其他字段（根据配置）
   ↓
4. 数据清洗和去重
   ↓
5. 返回结构化数据
```

**高级选项**:
- 自动滚动 - 加载更多内容
- 分页处理 - 自动翻页
- 等待时间 - 控制抓取速度
- 最大数量 - 限制抓取条数

### 3. 数据表格展示

**技术**: TanStack Table v8

**功能特性**:
- ✅ 行选择（Checkbox）
- ✅ 搜索过滤
- ✅ 列排序
- ✅ 分页显示
- ✅ 列宽调整

**数据操作**:
```javascript
// 行选择
const rowSelection = {
  selectedRowIds: {},
  onRowSelectionChange: (updater) => {
    // 更新选中状态
  }
};

// 导出选中行
const exportSelectedRows = () => {
  const selectedData = table.getSelectedRowModel().rows
    .map(row => row.original);
  // 导出为 CSV/JSON
};
```

### 4. 多格式导出

**支持格式**:

#### CSV 导出
```javascript
import Papa from 'papaparse';

const exportToCSV = (data) => {
  const csv = Papa.unparse(data, {
    header: true,
    encoding: 'UTF-8'
  });
  // 下载文件
};
```

#### JSON 导出
```javascript
const exportToJSON = (data) => {
  const json = JSON.stringify(data, null, 2);
  // 下载文件
};
```

#### API 导出
```javascript
const exportToAPI = async (data, apiUrl) => {
  const response = await fetch(apiUrl, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(data)
  });
  // 处理响应
};
```

### 5. 地理位置信息

**功能**: 自动提取或手动填写省市区信息

**提取策略**:
```javascript
extractLocationInfo() {
  // 1. 查找页面中的地理位置关键词
  const locationKeywords = ['省', '市', '县', '区'];
  
  // 2. 扫描页面文本
  // 3. 匹配地理位置模式
  // 4. 返回提取结果
}
```

**用户输入**:
- 导出时弹出输入框
- 自动填充提取到的内容
- 用户可编辑或重新输入
- 格式: `省 > 市 > 县`

---

## 技术实现细节

### 1. 消息传递机制

**Chrome Extension 消息流**:

```
Popup → Background → Content Script
  ↓         ↓              ↓
用户操作   消息路由      DOM操作
  ↓         ↓              ↓
Content Script → Background → Popup
  ↓         ↓              ↓
数据返回   消息转发      UI更新
```

**实现代码**:
```javascript
// Popup 发送消息
chrome.tabs.sendMessage(tabId, {
  action: 'startScraping',
  scraper: scraperConfig,
  selector: customSelector
}, (response) => {
  // 处理响应
});

// Content Script 接收消息
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.action === 'startScraping') {
    startScraping(request.scraper, sendResponse);
    return true; // 保持通道开放（异步响应）
  }
});
```

### 2. DOM 选择器策略

**智能选择器生成**:
```javascript
function generateSelectors(element) {
  // 优先级策略
  const selectors = [];
  
  // 1. ID 选择器（最精确）
  if (element.id) {
    selectors.push(`#${element.id}`);
  }
  
  // 2. Class 选择器
  if (element.className) {
    const classes = element.className.split(' ')
      .filter(c => c && !c.includes(' '))
      .map(c => `.${c}`);
    selectors.push(...classes);
  }
  
  // 3. 属性选择器
  if (element.hasAttribute('data-*')) {
    // 使用 data 属性
  }
  
  // 4. 标签 + 位置选择器
  selectors.push(`${element.tagName.toLowerCase()}:nth-child(${index})`);
  
  return selectors;
}
```

### 3. 数据提取算法

**列表项识别**:
```javascript
async scrapeList() {
  // 1. 确定列表容器
  const container = document.querySelector(this.customSelector || this.findListContainer());
  
  // 2. 识别列表项
  const items = container.querySelectorAll('li, tr, div[class*="item"]');
  
  // 3. 提取数据
  const data = Array.from(items).map(item => {
    return {
      title: this.extractTitle(item),
      href: this.extractLink(item),
      // ... 其他字段
    };
  });
  
  // 4. 去重
  return this.deduplicate(data);
}
```

**字段提取**:
```javascript
extractTitle(element) {
  // 优先级顺序
  const selectors = [
    'a', 'h1', 'h2', 'h3', 'h4',
    '[class*="title"]', '[class*="name"]',
    '.title', '.name'
  ];
  
  for (const selector of selectors) {
    const found = element.querySelector(selector);
    if (found && found.textContent.trim()) {
      return found.textContent.trim();
    }
  }
  
  // 回退：使用元素自身文本
  return element.textContent.trim();
}
```

### 4. 存储管理

**Chrome Storage API**:
```javascript
// 保存抓取器配置
chrome.storage.local.set({
  scrapers: scrapersArray
});

// 读取配置
chrome.storage.local.get(['scrapers'], (result) => {
  const scrapers = result.scrapers || [];
});
```

**数据结构**:
```javascript
{
  scrapers: [
    {
      id: 'unique-id',
      name: '抓取器名称',
      type: 'list', // 或 'details'
      domain: 'example.com',
      options: {
        maxItems: 100,
        autoScroll: true,
        waitTime: 2000
      },
      createdAt: '2025-01-01T00:00:00Z'
    }
  ]
}
```

---

## 数据流程

### 完整抓取流程

```
┌─────────────┐
│  用户操作    │
│ 点击"开始抓取"│
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  Popup UI       │
│  发送抓取请求    │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│ Background      │
│  消息路由        │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│ Content Script  │
│  1. 识别列表容器  │
│  2. 提取列表项    │
│  3. 提取字段数据  │
│  4. 数据清洗      │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  返回数据        │
│  [{title, href}] │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  Popup UI       │
│  展示在表格中    │
└─────────────────┘
```

### 导出流程

```
┌─────────────┐
│  用户选择导出  │
│  CSV/JSON/API │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  获取选中数据    │
│  (或全部数据)    │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  地理位置输入    │
│  (可选)          │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  格式化数据      │
│  + location     │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│  导出执行        │
│  - 下载文件      │
│  - 或 POST API  │
└─────────────────┘
```

---

## API 集成

### 后端接口规范

**请求格式**:
```http
POST /api/export-data HTTP/1.1
Content-Type: application/json

[
  {
    "title": "数据标题",
    "href": "https://example.com/detail/123",
    "location": "省 > 市 > 县"
  },
  ...
]
```

**响应格式**:
```json
{
  "success": true,
  "count": 10,
  "message": "成功导出 10 条数据"
}
```

### Python Flask 示例

```python
from flask import Flask, request, jsonify
from flask_cors import CORS

app = Flask(__name__)
CORS(app)  # 必须启用 CORS

@app.route('/api/export-data', methods=['POST'])
def export_data():
    try:
        data = request.json  # 直接是数组
        
        if not isinstance(data, list):
            return jsonify({
                'success': False,
                'error': '数据格式错误，期望数组'
            }), 400
        
        # 批量插入数据库
        success_count = insert_to_database(data)
        
        return jsonify({
            'success': True,
            'count': success_count,
            'message': f'成功导出 {success_count} 条数据'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500
```

### Location 字段处理

```python
def process_location(location_str):
    """解析地理位置字符串"""
    if not location_str:
        return None
    
    parts = location_str.split(' > ')
    
    if len(parts) == 3:
        return {
            'province': parts[0],
            'city': parts[1],
            'district': parts[2]
        }
    # ... 处理不完整的情况
```

---

## 特色功能

### 1. Playwright 配置导出

**功能价值**: 将插件测试成功的网站配置导出为 JSON，直接用于后端 Playwright 脚本开发

**导出内容**:
```json
{
  "website": "example.gov.cn",
  "selectors": {
    "listContainer": "#list",
    "listItem": "li",
    "fields": {
      "title": "a",
      "link": "a[href]"
    }
  },
  "pagination": {
    "enabled": true,
    "nextButton": "a:contains('下一页')"
  },
  "waitConfig": {
    "listLoad": 2000
  },
  "playwrightTemplate": {
    "code": "# 完整的 Python 代码..."
  }
}
```

**使用场景**:
1. 插件测试网站 → 5分钟
2. 导出配置 → 1分钟
3. 后端使用配置 → 5分钟
4. **总计: 11分钟 vs 传统方式 3-5小时**

### 2. 搜索关键词快捷选择

**功能**: 自动识别页面搜索框，添加快捷关键词按钮

**预定义关键词**:
- 耕地地力
- 大豆玉米
- 稻谷补贴
- 粮食生产
- 粮油规模
- 小麦一喷三防
- 油菜

**实现逻辑**:
```javascript
addSearchKeywordHelper() {
  // 1. 识别搜索框
  const searchInputs = document.querySelectorAll(
    'input[type="text"], input[type="search"], ' +
    'input[name*="search"], input[name*="keyword"]'
  );
  
  // 2. 在每个搜索框上方添加关键词按钮
  searchInputs.forEach(input => {
    const helper = createKeywordHelper(input);
    input.parentNode.insertBefore(helper, input);
  });
}
```

### 3. 多环境支持

**环境配置**:
- 测试环境 (`env:test`)
- 开发环境 (`env:dev`)
- 生产环境 (`env:prod`)

**切换方式**:
```bash
npm run env:test  # 切换到测试环境并重新编译
npm run env:dev   # 切换到开发环境
npm run env:prod  # 切换到生产环境
```

**配置文件**: `src/config/api.js`
```javascript
const configs = {
  test: { apiUrl: 'http://localhost:5000' },
  dev: { apiUrl: 'http://dev.example.com' },
  prod: { apiUrl: 'https://api.example.com' }
};
```

---

## 使用场景

### 场景 1: 政府网站数据采集

**需求**: 采集各地政府网站的农业补贴政策信息

**流程**:
1. 访问政府网站搜索页面
2. 使用关键词快捷选择功能搜索"耕地地力"
3. 创建列表抓取器
4. 开始抓取搜索结果
5. 导出数据到后端 API
6. 后端批量入库

**优势**:
- 快速验证网站结构
- 无需编写爬虫代码
- 支持批量操作

### 场景 2: 电商商品数据采集

**需求**: 采集电商平台的商品列表信息

**流程**:
1. 访问商品列表页
2. 创建抓取器，配置字段（标题、价格、链接、图片）
3. 启用自动滚动加载更多
4. 抓取完成后导出 CSV
5. 数据分析

### 场景 3: 新闻资讯采集

**需求**: 定期采集新闻网站的资讯列表

**流程**:
1. 保存抓取器配置
2. 定期访问网站
3. 使用已保存的抓取器
4. 一键抓取最新数据
5. 导出到数据库

### 场景 4: 开发辅助工具

**需求**: 为新网站开发 Playwright 爬虫脚本

**流程**:
1. 用插件测试网站（5分钟）
2. 确认能正确抓取数据
3. 导出 Playwright 配置
4. 后端直接使用配置生成脚本
5. **节省 95% 开发时间**

---

## 技术亮点总结

### 1. 架构设计

- ✅ **模块化设计** - Popup、Content、Background 职责清晰
- ✅ **消息驱动** - 使用 Chrome Extension 消息机制实现通信
- ✅ **状态管理** - 基于 Chrome Storage API 的持久化存储

### 2. 用户体验

- ✅ **零学习成本** - 可视化操作，无需编程
- ✅ **智能识别** - 自动检测列表结构
- ✅ **灵活选择** - 支持多容器选择、行选择
- ✅ **实时反馈** - 抓取进度、错误提示

### 3. 开发效率

- ✅ **配置复用** - 抓取器配置可保存和复用
- ✅ **配置导出** - 导出 Playwright 配置，加速后端开发
- ✅ **多环境支持** - 测试/开发/生产环境切换

### 4. 数据质量

- ✅ **数据清洗** - 自动去重、格式化
- ✅ **字段提取** - 智能识别标题、链接等字段
- ✅ **地理位置** - 自动提取或手动填写省市区信息

### 5. 扩展性

- ✅ **插件化架构** - 易于添加新功能
- ✅ **API 集成** - 支持自定义后端接口
- ✅ **多格式导出** - CSV、JSON、API 多种方式

---

## 性能优化

### 1. 数据抓取优化

- **批量处理** - 一次性提取所有列表项，而非逐个处理
- **选择器缓存** - 缓存常用的 DOM 选择器
- **延迟加载** - 支持自动滚动加载更多内容

### 2. 内存管理

- **数据分页** - 表格支持分页，避免一次性渲染大量数据
- **及时清理** - 抓取完成后清理临时数据

### 3. 用户体验优化

- **异步处理** - 所有耗时操作异步执行，不阻塞 UI
- **进度反馈** - 实时显示抓取进度
- **错误处理** - 完善的错误提示和恢复机制

---

## 未来规划

### 短期优化

- [ ] 支持更多数据格式（Excel、XML）
- [ ] 增加数据预览功能
- [ ] 支持自定义字段映射
- [ ] 增加数据验证规则

### 长期规划

- [ ] AI 智能识别 - 使用机器学习优化列表识别
- [ ] 云端配置同步 - 多设备配置同步
- [ ] 协作功能 - 团队共享抓取器配置
- [ ] 定时任务 - 支持定时自动抓取

---

## 总结

**Data Hunter Pro** 是一个功能完善、技术先进的网页数据抓取工具，通过智能识别、灵活配置、多格式导出等特性，为用户提供了高效的数据采集解决方案。特别是 **Playwright 配置导出** 功能，将插件从单纯的数据采集工具升级为完整的开发辅助工具链，大大提升了后端爬虫开发的效率。

**核心优势**:
- 🚀 **开发效率提升 20 倍** - 从 3-5 小时缩短到 10-15 分钟
- 🎯 **零代码操作** - 可视化界面，无需编程知识
- 🔧 **开发辅助** - 导出配置，加速后端开发
- 📊 **数据质量** - 智能清洗、去重、格式化

---

**文档版本**: v1.0  
**最后更新**: 2025-01-XX  
**维护者**: Data Hunter Pro Team


